{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef608c5c-7b0a-4ba7-8b64-4969fa9f95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2a211d-28d4-4af4-9d8b-ca8caf4f269b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/20 22:26:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "\n",
    "spark = spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab2\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40a4620-6227-42ff-8808-2c95ed188764",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatePath = 'candidate.json'\n",
    "queryPath = 'query.json'\n",
    "stopwordPath = 'stopwords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d05d5cc0-07c5-457c-a7eb-66e48de6eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = spark.read.option(\"multiline\", \"true\").json(candidatePath)\n",
    "candidates = candidates.withColumn('abstract', F.trim('abstract'))\n",
    "\n",
    "queries = spark.read.option(\"multiline\", \"true\").json(queryPath)\n",
    "queries = queries.withColumn('abstract', F.trim('abstract'))\n",
    "\n",
    "with open(stopwordPath, 'r') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b57efcff-b5ad-4203-bfe5-3ae6760d603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(row):\n",
    "    abstract = row['abstract']\n",
    "    sentences = sent_tokenize(abstract)\n",
    "    return Row(abstract=abstract, sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d988e1db-f87e-491f-9a1c-2308bb4c1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2array(row):\n",
    "    abstract = row['abstract']\n",
    "    final_tokens = tuple(row['final_tokens'])\n",
    "    id = row['id']\n",
    "    return Row(id=id, abstract=abstract, tokens=final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "468ae853-9702-4cf2-9057-f15176e1caac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer_ab4fbb977a84"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(outputCol=\"tokens\")\n",
    "tokenizer.setInputCol('abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d57db7f-ca94-46dd-9bc4-9b5546d8bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_tokenized = tokenizer.transform(candidates)\n",
    "candidates_tokenized = candidates_tokenized.withColumn('final_tokens', F.array_except('tokens', F.lit(stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "472b0401-24fb-4fa7-b9c7-6a61aadc12aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The $3x+1$ Problem asks if whether for every n...</td>\n",
       "      <td>1504.03040</td>\n",
       "      <td>[the, $3x+1$, problem, asks, if, whether, for,...</td>\n",
       "      <td>[$3x+1$, problem, asks, natural, number, $n$,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We characterize the terahertz detection mechan...</td>\n",
       "      <td>1203.6290</td>\n",
       "      <td>[we, characterize, the, terahertz, detection, ...</td>\n",
       "      <td>[characterize, terahertz, detection, mechanism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper proposes LPRNet - end-to-end method...</td>\n",
       "      <td>1806.10447</td>\n",
       "      <td>[this, paper, proposes, lprnet, -, end-to-end,...</td>\n",
       "      <td>[paper, proposes, lprnet, -, end-to-end, metho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We develop the representation of bulk fields w...</td>\n",
       "      <td>1204.0126</td>\n",
       "      <td>[we, develop, the, representation, of, bulk, f...</td>\n",
       "      <td>[develop, representation, bulk, fields, spin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We present a cascade model for turbulence in w...</td>\n",
       "      <td>0707.3149</td>\n",
       "      <td>[we, present, a, cascade, model, for, turbulen...</td>\n",
       "      <td>[cascade, model, turbulence, weakly, collision...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract          id  \\\n",
       "0  The $3x+1$ Problem asks if whether for every n...  1504.03040   \n",
       "1  We characterize the terahertz detection mechan...   1203.6290   \n",
       "2  This paper proposes LPRNet - end-to-end method...  1806.10447   \n",
       "3  We develop the representation of bulk fields w...   1204.0126   \n",
       "4  We present a cascade model for turbulence in w...   0707.3149   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [the, $3x+1$, problem, asks, if, whether, for,...   \n",
       "1  [we, characterize, the, terahertz, detection, ...   \n",
       "2  [this, paper, proposes, lprnet, -, end-to-end,...   \n",
       "3  [we, develop, the, representation, of, bulk, f...   \n",
       "4  [we, present, a, cascade, model, for, turbulen...   \n",
       "\n",
       "                                        final_tokens  \n",
       "0  [$3x+1$, problem, asks, natural, number, $n$,,...  \n",
       "1  [characterize, terahertz, detection, mechanism...  \n",
       "2  [paper, proposes, lprnet, -, end-to-end, metho...  \n",
       "3  [develop, representation, bulk, fields, spin, ...  \n",
       "4  [cascade, model, turbulence, weakly, collision...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_tokenized.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ea5d630-a9a9-42db-bf0a-fe66cf3f30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_rdd = candidates_tokenized.limit(5).rdd.map(list2array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c583494-e8b1-41ee-931e-dc0ba7a6e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_tokenized = tokenizer.transform(queries)\n",
    "queries_tokenized = queries_tokenized.withColumn('final_tokens', F.array_except('tokens', F.lit(stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "247da2ff-6161-4f23-bcd4-078d92bd6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_rdd = queries_tokenized.limit(5).rdd.map(list2array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0966e9df-9a63-403f-85d9-b7bfeaf9b937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(a='A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', b=5),\n",
       " Row(a=\"Partial cubes are isometric subgraphs of hypercubes. Structures on a graph\\ndefined by means of semicubes, and Djokovi\\\\'{c}'s and Winkler's relations play\\nan important role in the theory of partial cubes. These structures are employed\\nin the paper to characterize bipartite graphs and partial cubes of arbitrary\\ndimension. New characterizations are established and new proofs of some known\\nresults are given.\\n  The operations of Cartesian product and pasting, and expansion and\\ncontraction processes are utilized in the paper to construct new partial cubes\\nfrom old ones. In particular, the isometric and lattice dimensions of finite\\npartial cubes obtained by means of these operations are calculated.\\n\", b=5),\n",
       " Row(a='We study the two-particle wave function of paired atoms in a Fermi gas with\\ntunable interaction strengths controlled by Feshbach resonance. The Cooper pair\\nwave function is examined for its bosonic characters, which is quantified by\\nthe correction of Bose enhancement factor associated with the creation and\\nannihilation composite particle operators. An example is given for a\\nthree-dimensional uniform gas. Two definitions of Cooper pair wave function are\\nexamined. One of which is chosen to reflect the off-diagonal long range order\\n(ODLRO). Another one corresponds to a pair projection of a BCS state. On the\\nside with negative scattering length, we found that paired atoms described by\\nODLRO are more bosonic than the pair projected definition. It is also found\\nthat at $(k_F a)^{-1} \\\\ge 1$, both definitions give similar results, where more\\nthan 90% of the atoms occupy the corresponding molecular condensates.\\n', b=5),\n",
       " Row(a='A rather non-standard quantum representation of the canonical commutation\\nrelations of quantum mechanics systems, known as the polymer representation has\\ngained some attention in recent years, due to its possible relation with Planck\\nscale physics. In particular, this approach has been followed in a symmetric\\nsector of loop quantum gravity known as loop quantum cosmology. Here we explore\\ndifferent aspects of the relation between the ordinary Schroedinger theory and\\nthe polymer description. The paper has two parts. In the first one, we derive\\nthe polymer quantum mechanics starting from the ordinary Schroedinger theory\\nand show that the polymer description arises as an appropriate limit. In the\\nsecond part we consider the continuum limit of this theory, namely, the reverse\\nprocess in which one starts from the discrete theory and tries to recover back\\nthe ordinary Schroedinger quantum mechanics. We consider several examples of\\ninterest, including the harmonic oscillator, the free particle and a simple\\ncosmological model.\\n', b=5),\n",
       " Row(a='A general formulation was developed to represent material models for\\napplications in dynamic loading. Numerical methods were devised to calculate\\nresponse to shock and ramp compression, and ramp decompression, generalizing\\nprevious solutions for scalar equations of state. The numerical methods were\\nfound to be flexible and robust, and matched analytic results to a high\\naccuracy. The basic ramp and shock solution methods were coupled to solve for\\ncomposite deformation paths, such as shock-induced impacts, and shock\\ninteractions with a planar interface between different materials. These\\ncalculations capture much of the physics of typical material dynamics\\nexperiments, without requiring spatially-resolving simulations. Example\\ncalculations were made of loading histories in metals, illustrating the effects\\nof plastic work on the temperatures induced in quasi-isentropic and\\nshock-release experiments, and the effect of a phase transition.\\n', b=5)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toList(a):\n",
    "    return [a]\n",
    "def append(a, b):\n",
    "    a.append(b)\n",
    "    return a\n",
    "def extend(a, b):\n",
    "    a.extend(b)\n",
    "    return a\n",
    "queries_rdd.cartesian(candidates_rdd).combineByKey(toList, append, extend).map(docTFIDF).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd1237f4-04af-426c-af0d-c4012b0987d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docTFIDF(row):\n",
    "    return Row(a=row[0]['abstract'], b=len(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb2380-bd91-4e0b-bd13-6ae908427bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calMostSimilar(row):\n",
    "    query = row[0]\n",
    "    docs = row[1]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
